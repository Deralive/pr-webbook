import os
import uuid
import re


def envs_cover(line: str) -> str:
    """
    å°† LaTeX ç¯å¢ƒè½¬æ¢ä¸º Markdown ç¯å¢ƒ

    Notice: è¿™ä¸ªç¯å¢ƒæ›¿æ¢æ˜¯é€è¡Œæ£€æµ‹çš„ï¼Œè¿™é‡Œå®šä¹‰çš„éƒ½æ˜¯é€è¡Œæ›¿æ¢çš„ Pattern.
    """
    patterns = {
        # Comment Ignore
        r'^%.*': '',

        # Math Environments
        # Definition
        r'\\begin\{definition\}\s*\{(.+?)\}\s*\\label\s*\{(.+?)\}': r'\n\1\n: ',
        r'\\begin\{definition\}\s*\\label\s*\{(.+?)\}': r'\n\1\n: ',
        r'\\begin\{definition\}\s*\{(.+?)\}': r'\n\1\n: ',
        r'\\begin\{definition\}': '',
        r'\\end\{definition\}': '',

        # Example
        r'\\begin\{example\}\s*\{(.+?)\}\s*\\label\s*\{(.+?)\}': r'\n`````{prf:example} \1\n:label: \2',
        r'\\begin\{example\}\s*\[(.+?)\]': r'\n`````{prf:example} \1',
        r'\\begin\{example\}\s*\{(.+?)\}': r'\n`````{prf:example} \1',
        r'\\begin\{example\}\s*\\label\s*\{(.+?)\}': r'\n`````{prf:example} \n:label: \1',
        r'\\begin\{example\}': r'\n`````{prf:example}',
        r'\\end\{example\}': r'`````\n',

        # Property
        r'\\begin\{property\}\s*\{(.+?)\}\s*\\label\s*\{(.+?)\}': r'\n`````{prf:property} \1\n:label: \2',
        r'\\begin\{property\}\s*\\label\s*\{(.+?)\}': r'\n`````{prf:property} \n:label: \1',
        r'\\begin\{property\}\s*\{(.+?)\}': r'\n`````{prf:property} \1',
        r'\\begin\{property\}': '\n`````{prf:property}',
        r'\\end\{property\}': '`````\n',

        # Problem
        r'\\begin\{problem\}\s*\{(.+?)\}\s*\\label\s*\{(.+?)\}': r'\n```{admonition} Question \1\n:label: \2',
        r'\\begin\{problem\}\s*\\label\s*\{(.+?)\}': r'\n`````{prf:problem} \n:label: \1',
        r'\\begin\{problem\}\s*\{(.+?)\}': r'\n```{admonition} Question \1',
        r'\\begin\{problem\}': '\n```{admonition} Question',
        r'\\end\{problem\}': '```\n',

        # Lemma
        r'\\begin\{lemma\}\s*\{(.+?)\}\s*\\label\s*\{(.+?)\}': r'\n````` \1\n:label: \2',
        r'\\begin\{lemma\}\s*\\label\s*\{(.+?)\}': r'\n`````{prf:lemma} \n:label: \1',
        r'\\begin\{lemma\}\s*\{(.+?)\}': r'\n````` \1',
        r'\\begin\{lemma\}': '\n`````{prf:lemma}',
        r'\\end\{lemma\}': '`````\n',

        # Theorem
        r'\\begin\{theorem\}\{(.+?)\}\\label\{(.+?)\}': r'\n``````{prf:theorem} \1' + f'\n' + r':label: \2',
        r'\\begin\{theorem\}\s*\\label\s*\{(.+?)\}': r'\n`````{prf:theorem} \n:label: \1',
        r'\\begin\{theorem\}\[(.+?)\]': r'\n``````{prf:theorem} \1',
        r'\\begin\{theorem\}\{(.+?)\}': r'\n``````{prf:theorem} \1',
        r'\\begin\{theorem\}': '\n``````{prf:theorem}',
        r'\\end\{theorem\}': '``````\n',

        # Solve
        r'\\begin\{proof\}': '\n```{dropdown} Proof',
        r'\\end\{proof\}': '```',
        r'\\begin\{solution\}\s*(.*)': '\n```{dropdown} Solution\n\1',
        r'\\end\{solution\}': '```',
        r'\\begin\{remark\}': '\n```{admonition} Remark',
        r'\\end\{remark\}': '```\n',

        # Instance
        r'\\begin\{instance\}': '',
        r'\\end\{instance\}': '',
        r'\\begin\{conclusion\}': '',
        r'\\end\{conclusion\}': '',

        # Cross-ref
        r'\\ref\{(thm:.+?)\}': r' {prf:ref} `\1` ',
        r'\\ref\{(lem:.+?)\}': r' {prf:ref} `\1` ',
        r'\\ref\{(ex:.+?)\}': r' {prf:ref} `\1` ',
        r'\\ref\{(fig:.+?)\}': r' {numref}`\1` ',
        r'\\ref\{(tab:.+?)\}': r' {numref}`\1` ',

        # Enumerate and Itemize
        r'\\begin\{enumerate\}': '',
        r'\\end\{enumerate\}': '',
        r'\\begin\{itemize\}': '',
        r'\\end\{itemize\}': '',
        r'\\item': '- ',

        # Section
        r'\\chapter\{(.+?)\}': r'# \1',
        r'\\section\{(.+?)\}': r'# \1',
        r'\\subsection\{(.+?)\}': r'## \1',
        r'\\subsubsection\{(.+?)\}': r'### \1',

        # Note
        r'\\begin\{note\}': '',
        r'\\end\{note\}': '',

        # Vpsace
        r'\\vspace\{(.+?)\}': '',

        # Newpage
        r'\\newpage': '',

        # Bold
        r'\\textbf\{(.+?)\}': r'**\1**',
        r'\\bm\{(.+?)\}': r'\\mathbf{\1}',

        # Eqnarray
        r'\\begin\{eqnarray\*\}': r'$$' + f'\n' + r'\\begin{eqnarray*}',
        r'\\end\{eqnarray\*\}': r'\\end{eqnarray*}' + f'\n' + r'$$',

        # Introduction
        r'\\begin\{introduction}': r'```{admonition} æ•™æç´¢å¼•',
        r'\\end\{introduction}': '```',
        r'Intro to Prob': 'Introduction to Probability ',
        r'Prob\s+\\\&\s+Stat': 'æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡æ•™ç¨‹',
        r'Prob\s+\$\\\&\$\s+Stat': 'æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡æ•™ç¨‹',

        # ä¸­æ–‡å’Œè‹±æ–‡å•è¯ä¹‹é—´æ·»åŠ ç©ºæ ¼
        r'([\u4e00-\u9fff])([A-Za-z0-9]+)': r'\1 \2',
        r'([A-Za-z0-9]+)([\u4e00-\u9fff])': r'\1 \2',
    }

    for pattern, replacement in patterns.items():
        line = re.sub(pattern, replacement, line)

    if 'Introduction to Probability' in line or 'æ¦‚ç‡è®ºä¸æ•°ç†ç»Ÿè®¡æ•™ç¨‹' in line:
        line = line.replace('\\quad', ' ')

    return line


def tex_spliter(file_path: str) -> list:
    """
    å°† LateX æ–‡ä»¶çš„æ¯ä¸€è¡Œåˆ†å‰²å¼€ï¼Œä»¥ä¾¿åç»­å¤„ç†ï¼Œè¿”å›ä¸€ä¸ªåˆ—è¡¨
    """
    with open(file_path, 'r', encoding='utf-8') as file:
        lines = file.readlines()
    return [line.strip() for line in lines if line.strip()]


def one_dollar_replacer(text_content: str) -> str:
    """
    å¤„ç†æ–‡æœ¬å†…å®¹ï¼Œåœ¨æˆå¯¹çš„å•ç¾å…ƒç¬¦å·å‘¨å›´ä¿è¯æ­£å¥½ä¸€ä¸ªç©ºæ ¼ï¼Œ
    å¿½ç•¥åŒç¾å…ƒç¬¦å·($$)ï¼ŒåŒç¾å…ƒç¬¦å·ä¿æŒåŸæ ·ã€‚

    Tips: ç”±äºå»ºç«‹çš„æ•°å­¦ç¯å¢ƒé€šå¸¸æœ‰å¤šè¡Œï¼Œæ•…ä¸èƒ½ä½¿ç”¨ Line Pattern å¤„ç†ã€‚
    """
    placeholder = f"__DOUBLE_DOLLAR_PLACEHOLDER_{uuid.uuid4().hex}__"
    # ä¿æŠ¤æ‰€æœ‰åŒç¾å…ƒç¬¦å·
    text_with_placeholders = text_content.replace('$$', placeholder)

    def replacer(match):
        content = match.group(1)
        # å»é™¤å†…å®¹ä¸¤ç«¯ç©ºç™½
        content_stripped = content.strip()
        return f' ${content_stripped}$ '

    processed_text = re.sub(r'\$(.+?)\$', replacer, text_with_placeholders)

    # å°†åŒç¾å…ƒç¬¦å·è¿˜åŸ
    final_text = processed_text.replace(placeholder, '$$')

    # ç”¨æ­£åˆ™æ›¿æ¢æ‰€æœ‰å…¬å¼å¤–ä¸¤è¾¹è¿ç»­ç©ºæ ¼ä¸º1ä¸ªç©ºæ ¼
    final_text = re.sub(r'(?<=\S) {2,}(?=\S)', ' ', final_text)
    return final_text


def two_dollar_replacer(cont: str) -> str:
    """
    ä¸º Markdown å†…å®¹ä¸­çš„ $$...$$ æ•°å­¦å…¬å¼å—å‰åæ·»åŠ ç©ºè¡Œã€‚
    ç¡®ä¿å…¬å¼å—ä¸Šä¸‹å„æœ‰ä¸€ä¸ªç©ºè¡Œã€‚
    """
    # 1. åœ¨æ¯ä¸ªåŒ¹é…çš„æ•°å­¦å…¬å¼å—ï¼ˆ$$...$$ï¼‰å‰åæ’å…¥ä¸¤ä¸ªæ¢è¡Œç¬¦
    # 2. å°†ä¸‰ä¸ªæˆ–æ›´å¤šè¿ç»­çš„æ¢è¡Œç¬¦æ›¿æ¢ä¸ºä¸¤ä¸ªï¼ˆå³ä¸€ä¸ªç©ºè¡Œï¼‰ï¼Œä»¥æ•´ç†æ ¼å¼
    # 3. ç§»é™¤å­—ç¬¦ä¸²é¦–å°¾å¯èƒ½å­˜åœ¨çš„å¤šä½™æ¢è¡Œç¬¦
    content = re.sub(r"(\$\$.*?\$\$)", r"\n\n\1\n\n", cont, flags=re.DOTALL)
    content = re.sub(r"\n{3,}", r"\n\n", content)
    content = content.strip('\n')
    return content

def merge_solution_or_proof_into_example_or_theorem(content: str) -> str:
    merge_rules = [
        {
            # åŒ¹é… {prf:example} å—ï¼Œå…¶åç´§è·Ÿç€ä¸€ä¸ª Solution æˆ– Proof çš„ dropdown
            "pattern": re.compile(r"(`````\{prf:example\}.*?)\n`````\s*(```\{dropdown\} (?:Solution|Proof).*?\n```)", re.DOTALL),
            "replacement": r"\1\n\2\n`````"
        },
        {
            # åŒ¹é… {prf:theorem} å—ï¼Œå…¶åç´§è·Ÿç€ä¸€ä¸ª Solution æˆ– Proof çš„ dropdown
            "pattern": re.compile(r"(``````\{prf:theorem\}.*?)\n``````\s*(```\{dropdown\} (?:Solution|Proof).*?\n```)", re.DOTALL),
            "replacement": r"\1\n\2\n``````"
        },
        {
            # åŒ¹é… {prf:definition} å—ï¼Œå…¶åç´§è·Ÿç€ä¸€ä¸ª Solution æˆ– Proof çš„ dropdown
            "pattern": re.compile(r"(`````\{prf:definition\}.*?)\n`````\s*(```\{dropdown\} (?:Solution|Proof).*?\n```)", re.DOTALL),
            "replacement": r"\1\n\2\n`````"
        },
        {
            # åŒ¹é… {prf:property} å—ï¼Œå…¶åç´§è·Ÿç€ä¸€ä¸ª Solution æˆ– Proof çš„ dropdown
            "pattern": re.compile(r"(`````\{prf:property\}.*?)\n`````\s*(```\{dropdown\} (?:Solution|Proof).*?\n```)", re.DOTALL),
            "replacement": r"\1\n\2\n`````"
        },
        {
            # åŒ¹é… {prf:problem} å—ï¼Œå…¶åç´§è·Ÿç€ä¸€ä¸ª Solution æˆ– Proof çš„ dropdown
            "pattern": re.compile(r"(```\{admonition\} Question.*?)\n```.*?\s*(```\{dropdown\} (?:Solution|Proof).*?\n```)", re.DOTALL),
            "replacement": r"\1\n\2\n```"
        },
    ]

    # ä½¿ç”¨ while å¾ªç¯ï¼Œåå¤åº”ç”¨è§„åˆ™ï¼Œç›´åˆ°å†…å®¹ä¸å†å‘ç”Ÿå˜åŒ–ã€‚
    # è¿™å¯ä»¥æ­£ç¡®å¤„ç†ä¸€ä¸ªç¯å¢ƒå—åé¢è·Ÿç€å¤šä¸ªä¸‹æ‹‰å—çš„æƒ…å†µ (ä¾‹å¦‚ï¼Œå…ˆ Proofï¼Œå† Solution)ã€‚
    while True:
        original_content = content
        for rule in merge_rules:
            content = rule["pattern"].sub(rule["replacement"], content)

        if content == original_content:
            break

    return content

def fix_definition_format(content: str) -> str:
    """
    åå¤„ç†å‡½æ•°ï¼Œç”¨äºä¿®å¤ definition ç¯å¢ƒçš„æ ¼å¼ã€‚
    å°† "Title\n: \nContent" æ¨¡å¼è½¬æ¢ä¸º "Title\n: Content"ã€‚
    """
    content = re.sub(r'(.*?)\n\s*:\s*\n\s*(.+)', r'\1\n: \2', content, flags=re.DOTALL)
    return content


def process_figure_environments(content: str) -> str:
    """
    å¤„ç† LaTeX çš„ figure ç¯å¢ƒï¼Œè½¬æ¢ä¸º Jupyter Book çš„ {figure} æŒ‡ä»¤ã€‚
    ã€å·²ä¿®æ­£ã€‘å¯ä»¥å¤„ç† \label åœ¨ \caption å†…éƒ¨æˆ–å¤–éƒ¨çš„æƒ…å†µï¼Œå¹¶å¼ºåˆ¶è¦æ±‚æ ‡ç­¾ä»¥ "fig:" å¼€å¤´ã€‚
    """
    # åŒ¹é…æ•´ä¸ª figure ç¯å¢ƒå—
    figure_block_pattern = re.compile(
        r'(\\begin\{figure\}.*?\\end\{figure\})',
        re.DOTALL
    )

    def replace_figure_block(match):
        figure_block = match.group(1)

        # 1. ä»å—ä¸­ç‹¬ç«‹æå–å›¾ç‰‡è·¯å¾„ã€æ ‡é¢˜å’Œæ ‡ç­¾
        image_match = re.search(r'\\includegraphics(?:\[.*?\])?\{(.+?)\}', figure_block, re.DOTALL)
        caption_match = re.search(r'\\caption\{(.*?)\}', figure_block, re.DOTALL)
        # ã€å…³é”®ä¿®æ”¹ã€‘åœ¨è¿™é‡Œçš„æ­£åˆ™è¡¨è¾¾å¼ä¸­ï¼Œæˆ‘ä»¬å¼ºåˆ¶è¦æ±‚ label å¿…é¡»ä»¥ "fig:" å¼€å¤´
        label_match = re.search(r'\\label\{(fig:.+?)\}', figure_block, re.DOTALL)

        # å¦‚æœç¼ºå°‘ä»»ä½•å…³é”®éƒ¨åˆ†ï¼Œåˆ™ä¸è¿›è¡Œè½¬æ¢ï¼Œè¿”å›åŸæ–‡
        if not image_match or not caption_match or not label_match:
            return figure_block

        image_path_raw = image_match.group(1).strip()
        full_caption_content = caption_match.group(1)
        label_name = label_match.group(1)  # ä¾‹å¦‚ "fig:myfigure"

        # 2. æ¸…ç†æ•°æ®
        # ä»æ ‡é¢˜ä¸­ç§»é™¤ \label å‘½ä»¤
        caption_text = full_caption_content.replace(f'\\label{{{label_name}}}', '').strip()
        # ä¸è¦ä¸º :name: æŒ‡ä»¤ç§»é™¤ 'fig:' å‰ç¼€
        transformed_label_name = label_name

        # å¤„ç†å›¾ç‰‡è·¯å¾„
        transformed_image_path = image_path_raw.replace('image/', '/fig/')
        if transformed_image_path.lower().endswith('.pdf'):
            transformed_image_path = transformed_image_path[:-4] + '.png'

        # 3. æ„å»º figure æŒ‡ä»¤
        markdown_figure = (
            f'```{{figure}} {transformed_image_path}\n'
            f':name: {transformed_label_name}\n\n'
            f'{caption_text}\n'
            f'```'
        )
        return markdown_figure

    return figure_block_pattern.sub(replace_figure_block, content)


def process_table_environments(content: str) -> str:
    """
    å¤„ç† LaTeX çš„ table ç¯å¢ƒï¼Œè½¬æ¢ä¸º Jupyter Book çš„ {list-table} æŒ‡ä»¤ã€‚
    ã€æœ€ç»ˆä¿®æ­£ç‰ˆã€‘
    1. å¯å¤„ç† \label åœ¨ \caption å†…éƒ¨æˆ–å¤–éƒ¨çš„æƒ…å†µï¼Œå¹¶å¼ºåˆ¶è¦æ±‚ "tab:" å‰ç¼€ã€‚
    2. å¯æ¸…ç† \toprule, \multicolumn, \cline ç­‰é«˜çº§ LaTeX è¡¨æ ¼å‘½ä»¤ã€‚
    """
    # åŒ¹é…æ•´ä¸ª table ç¯å¢ƒå—
    table_block_pattern = re.compile(
        r'(\\begin\{table\}.*?\\end\{table\})',
        re.DOTALL
    )

    def replace_table_block(match):
        table_block = match.group(1)

        # 1. ä»å—ä¸­ç‹¬ç«‹æå–æ ‡é¢˜ã€æ ‡ç­¾å’Œå†…å®¹
        caption_match = re.search(r'\\caption\{(.*?)\}', table_block, re.DOTALL)
        label_match = re.search(r'\\label\{(tab:.+?)\}', table_block, re.DOTALL)
        tabular_match = re.search(r'\\begin\{tabular\}.*?\}(.*?)\\end\{tabular\}', table_block, re.DOTALL)

        if not caption_match or not label_match or not tabular_match:
            return table_block

        full_caption_content = caption_match.group(1)
        label_name = label_match.group(1)
        tabular_content_raw = tabular_match.group(1).strip()

        # 2. æ¸…ç†æ ‡é¢˜å’Œæ ‡ç­¾ (è§£å†³é—®é¢˜1)
        caption_text = full_caption_content.replace(f'\\label{{{label_name}}}', '').strip()
        transformed_label_name = label_name[4:] if label_name.startswith('tab:') else label_name

        # 3. æ¸…ç†è¡¨æ ¼å†…å®¹ä¸­çš„é«˜çº§ LaTeX å‘½ä»¤ (è§£å†³é—®é¢˜2)
        # ç§»é™¤ \toprule, \midrule, \bottomrule
        cleaned_content = re.sub(r'\\(top|mid|bottom)rule', '', tabular_content_raw)
        # ç§»é™¤ \cline{...}
        cleaned_content = re.sub(r'\\cline\{.*?\}', '', cleaned_content)
        # å°† \multicolumn{...}{...}{...} æ›¿æ¢ä¸ºå…¶å†…å®¹
        cleaned_content = re.sub(r'\\multicolumn\{.+?\}\{.+?\}\{(.+?)\}', r'\1', cleaned_content)
        # ç§»é™¤é—ç•™çš„ \hline
        cleaned_content = re.sub(r'\\hline', '', cleaned_content).strip()

        # 4. è§£æè¡¨æ ¼çš„è¡Œå’Œåˆ—
        rows = [row.strip() for row in cleaned_content.split(r'\\') if row.strip()]

        markdown_table_rows = []
        header_rows_count = 1

        for row_str in rows:
            # {..} åœ¨ LaTeX ä¸­ç”¨äºåˆ†ç»„ï¼Œä½†åœ¨æˆ‘ä»¬çš„å†…å®¹ä¸­ä¸éœ€è¦ï¼Œç›´æ¥ç§»é™¤
            cleaned_row_str = row_str.replace('{', '').replace('}', '')
            cols = [col.strip() for col in cleaned_row_str.split('&')]
            formatted_cols = []
            if cols:
                formatted_cols.append(f'* - {cols[0]}')
                for col in cols[1:]:
                    formatted_cols.append(f'  - {col}')
            markdown_table_rows.append('\n'.join(formatted_cols))

        markdown_table_content = '\n'.join(markdown_table_rows)

        # 5. æ„å»ºæœ€ç»ˆçš„ list-table
        markdown_table = (
            f'```{{list-table}} {caption_text}\n'
            f':header-rows: {header_rows_count}\n'
            f':name: tab:{transformed_label_name}\n'
            f'{markdown_table_content}\n'
            f'```'
        )
        return markdown_table

    return table_block_pattern.sub(replace_table_block, content)

def process_single_tex_file(input_filename: str, output_dir: str) -> dict:
    """
    å¤„ç†å•ä¸ª .tex æ–‡ä»¶ï¼Œå°†å…¶æ‹†åˆ†ä¸ºç« èŠ‚å’ŒèŠ‚ï¼Œå¹¶è¿”å›ç”¨äºç”Ÿæˆç›®å½•çš„æ–‡ä»¶ç»“æ„ã€‚
    ã€V3 ç‰ˆé€»è¾‘ã€‘:
    - å¦‚æœæœ‰å°èŠ‚ï¼Œç¬¬ä¸€ä¸ªå°èŠ‚çš„å†…å®¹å†™å…¥ ChapterXX.mdã€‚
    - åç»­å°èŠ‚å†™å…¥ ChapterXXSectionYY.mdã€‚
    - å¦‚æœæ²¡æœ‰å°èŠ‚ï¼Œæ‰€æœ‰å†…å®¹å†™å…¥ ChapterXX.mdã€‚
    """
    if not os.path.exists(input_filename):
        print(f" æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {input_filename}")
        return None

    match = re.search(r'Lect(\d+)', input_filename)
    if not match:
        print(f" æ–‡ä»¶åæ ¼å¼ä¸ç¬¦ï¼Œè·³è¿‡: {input_filename}")
        return None
    base_output_name = f"Chapter{match.group(1)}"

    generated_files = []

    lines = tex_spliter(input_filename)
    processed_lines = [envs_cover(line) for line in lines]
    full_content = "\n".join(processed_lines)

    full_content = fix_definition_format(full_content)
    full_content = process_figure_environments(full_content)
    full_content = process_table_environments(full_content)

    section_heading_pattern = r'\n(?=#\s[^#])'
    sections = re.split(section_heading_pattern, full_content)

    preamble_content = ""
    if sections and sections[0].strip() and not sections[0].startswith('# '):
        preamble_content = sections.pop(0).strip()

    if not sections:
        # æƒ…å†µ1: æ–‡ä»¶ä¸­æ²¡æœ‰ä¸€çº§æ ‡é¢˜ (æ²¡æœ‰å°èŠ‚)
        # æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬å¯èƒ½çš„åºè¨€ï¼‰éƒ½å†™å…¥ä¸»æ–‡ä»¶
        if full_content.strip():
            filepath = f"{output_dir}{base_output_name}.md"
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(full_content)
            generated_files.append(filepath)
        chapter_toc_data = {"file": base_output_name}
    else:
        # æƒ…å†µ2: æ–‡ä»¶ä¸­æœ‰ä¸€ä¸ªæˆ–å¤šä¸ªä¸€çº§æ ‡é¢˜ (æœ‰å°èŠ‚)
        # ç¬¬ä¸€ä¸ªå°èŠ‚çš„å†…å®¹ï¼ˆåŠ ä¸Šåºè¨€ï¼‰å†™å…¥ä¸»æ–‡ä»¶
        first_section_content = sections.pop(0)
        main_file_content = (preamble_content + "\n\n" + first_section_content).strip()

        main_filepath = f"{output_dir}{base_output_name}.md"
        with open(main_filepath, "w", encoding="utf-8") as f:
            f.write(main_file_content)
        generated_files.append(main_filepath)

        # å‰©ä½™çš„å°èŠ‚ä» Section01 å¼€å§‹å‘½å
        section_files_for_toc = []
        for i, section_content in enumerate(sections, 1):
            if section_content.strip():
                section_base_name = f"{base_output_name}Section{i:02d}"
                section_filepath = f"{output_dir}{section_base_name}.md"
                with open(section_filepath, "w", encoding="utf-8") as f:
                    f.write(section_content.strip())
                generated_files.append(section_filepath)
                section_files_for_toc.append({"file": section_base_name})

        chapter_toc_data = {"file": base_output_name}
        if section_files_for_toc:
            chapter_toc_data["sections"] = section_files_for_toc

    # å¯¹æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶è¿›è¡Œæœ€ç»ˆçš„æ ¼å¼åŒ–å¤„ç†
    for file_path in generated_files:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        content = one_dollar_replacer(content)
        content = two_dollar_replacer(content)
        content = merge_solution_or_proof_into_example_or_theorem(content)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)

    print(f"  -> å·²å¤„ç† {len(generated_files)} ä¸ªæ–‡ä»¶ã€‚")
    return chapter_toc_data


def generate_toc_yml(chapters_data: list, output_file: str):
    """
    æ ¹æ®å¤„ç†å¥½çš„ç« èŠ‚æ•°æ®ï¼Œç”Ÿæˆå®Œæ•´çš„ _toc.yml æ–‡ä»¶ã€‚
    """
    # åŸºäºç”¨æˆ·ç¤ºä¾‹ï¼Œç¡¬ç¼–ç ç¬¬1-7ç« çš„ç»“æ„
    yml_content = """# ç›®å½•
# Learn more at [https://jupyterbook.org/customize/toc.html](https://jupyterbook.org/customize/toc.html)

format: jb-book
root: intro
parts:
  - caption: æ¦‚ç‡éƒ¨åˆ†
    numbered: True
    chapters:
    - file: Chapter01
      sections:
      - file: Chapter01Section01
      - file: Chapter01Section02
      - file: Chapter01Section03
      - file: Chapter01Section04
      - file: Chapter01Section05
      - file: Chapter01Section06
    - file: Chapter02
      sections:
      - file: Chapter02Section01
      - file: Chapter02Section02
      - file: Chapter02Section03
      - file: Chapter02Section04
      - file: Chapter02Section05
      - file: Chapter02Section06
      - file: Chapter02Section07
    - file: Chapter03
      sections:
      - file: Chapter03Section01
      - file: Chapter03Section02
    - file: Chapter04
      sections:
      - file: Chapter04Section01
      - file: Chapter04Section02
      - file: Chapter04Section03
      - file: Chapter04Section04
      - file: Chapter04Section05
      - file: Chapter04Section06
    - file: Chapter05
      sections:
      - file: Chapter05Section01
      - file: Chapter05Section02
      - file: Chapter05Section03
      - file: Chapter05Section04
    - file: Chapter06
      sections:
      - file: Chapter06Section01
      - file: Chapter06Section02
      - file: Chapter06Section03
      - file: Chapter06Section04
      - file: Chapter06Section05
      - file: Chapter06Section06
      - file: Chapter06Section07
      - file: Chapter06Section08
"""

    # åŠ¨æ€æ„å»ºå¹¶è¿½åŠ æ–°å¤„ç†çš„ç« èŠ‚ (07-24)
    for chapter in chapters_data:
        yml_content += f"    - file: {chapter['file']}\n"
        if "sections" in chapter and chapter["sections"]:
            yml_content += "      sections:\n"
            for section in chapter["sections"]:
                yml_content += f"      - file: {section['file']}\n"

    with open(output_file, "w", encoding="utf-8") as f:
        f.write(yml_content)

    print(f"\nâœ… æˆåŠŸç”Ÿæˆç›®å½•æ–‡ä»¶: {output_file}")


def process_simple_tex_file(input_filename: str, output_filename: str):
    """
    å¯¹å•ä¸ªç®€å•çš„ .tex æ–‡ä»¶è¿›è¡ŒåŸºç¡€å¤„ç†ï¼Œå¹¶ä¿å­˜ä¸º .md æ–‡ä»¶ã€‚
    å¤„ç†æµç¨‹:
    1. é€è¡Œåº”ç”¨ envs_cover ä¸­çš„æ­£åˆ™æ›¿æ¢ã€‚
    2. å¯¹å…¨æ–‡åº”ç”¨ one_dollar_replacerã€‚
    3. å¯¹å…¨æ–‡åº”ç”¨ two_dollar_replacerã€‚
    """
    try:
        with open(input_filename, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except FileNotFoundError:
        print(f"  âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {input_filename}")
        return

    # 1. é€è¡Œåº”ç”¨åŸºç¡€æ­£åˆ™æ›¿æ¢
    processed_lines = [envs_cover(line.strip()) for line in lines]
    full_content = "\n".join(processed_lines)

    # 2. & 3. åº”ç”¨ç¾å…ƒç¬¦å·æ ¼å¼åŒ–
    content_after_one_dollar = one_dollar_replacer(full_content)
    final_content = two_dollar_replacer(content_after_one_dollar)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir = os.path.dirname(output_filename)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    # å†™å…¥åˆ°è¾“å‡ºæ–‡ä»¶
    with open(output_filename, 'w', encoding='utf-8') as f:
        f.write(final_content)

    print(f"  âœ… ç®€å•å¤„ç†å®Œæˆï¼Œå·²ä¿å­˜è‡³: {output_filename}")


# ---------------------------------------------------------------------------
# Part 3: ä¸»å‡½æ•° - æµç¨‹æ§åˆ¶å™¨
# ---------------------------------------------------------------------------

def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºæ‰¹é‡å¤„ç† Lect08.tex åˆ° Lect24.texï¼Œå¹¶ç”Ÿæˆ _toc.ymlã€‚
    """
    output_dir = "../"
    toc_file_path = f"{output_dir}_toc.yml"
    all_chapters_data = []

    for i in range(7, 25):
        input_filename = f"Lect{i:02d}.tex"
        print(f"ğŸš€ æ­£åœ¨å¤„ç† {input_filename}...")

        chapter_data = process_single_tex_file(input_filename, output_dir)

        if chapter_data:
            all_chapters_data.append(chapter_data)

    if all_chapters_data:
        generate_toc_yml(all_chapters_data, toc_file_path)
    else:
        print("ï¸ æ²¡æœ‰æ–‡ä»¶è¢«æˆåŠŸå¤„ç†ï¼Œæ— æ³•ç”Ÿæˆ _toc.ymlã€‚")

def main2():
    """
    ä¸»å‡½æ•° 2ï¼Œç”¨äºå¤„ç†å•ä¸ªæ–‡ä»¶
    """
    input_filename = "temp.tex"
    output_dir = "../temp.md"
    print(f"ğŸš€ æ­£åœ¨å¤„ç† {input_filename}...")

    process_simple_tex_file(input_filename, output_dir)


if __name__ == '__main__':
    main2()