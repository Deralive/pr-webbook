\chapter{多维随机变量的特征数}
\begin{introduction}
  \item Intro to Prob\quad2.5 3.4 4.2
  \item Prob $\&$ Stat\quad 3.4
\end{introduction}
\section{回顾：一维随机变量函数的数学期望}
    若随机变量$X$的分布用分布列$p(x_i)$或密度函数$p(x)$表示，则$X$的某一函数$g(X)$的数学期望为
$$E(g(x))=\left\{\begin{aligned}
&\sum_{i} g\left(x_{i}\right) p\left(x_{i}\right), &\quad \text{在离散场合}, \\
&\int_{-\infty}^{+\infty} g(x) p(x) d x, &\quad \text{在连续场合}. 
\end{aligned}\right.$$

\section{多维随机向量函数的数学期望}
对一般多维随机向量函数的数学期望，我们可以类似于一维随机变量函数的数学期望定义。
\begin{theorem}
若多维随机变量$\bm{X}$的分布用联合分布列$P(\bm{X}=\bm{x})$或用联合密度函数$p(\bm{x})$表示，则$Z=g(\bm{X})$的数学期望为
$$E(Z)=\left\{
\begin{aligned}
    &\sum_{\bm{x}}  g\left(\bm{x}\right) P\left(\bm{X}=\bm{x}\right), & \text{在离散场合} \\
&\int_{R^n}  g(\bm{x}) p(\bm{x}) \text{d} \bm{x} , & \text{在连续场合}
\end{aligned}\right.$$
\end{theorem}
特别地，对于二维随机变量，我们定义其函数的期望如下。
\begin{theorem}
若二维随机变量$(X,Y)$的分布用联合分布列$P(X=x_{i},Y=y_{j})$或用联合密度函数$p(x,y)$表示，则$Z=g(X,Y)$的数学期望为
$$E(Z)=\left\{
\begin{aligned}
    &\sum_{i}  \sum_{j} g\left(x_{i}, y_{j}\right) P\left(X=x_{i}, Y=y_{j}\right), & \text{在离散场合} \\
&\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} g(x, y) p(x, y) \text{d} x \text{d} y,& \text{在连续场合}
\end{aligned}\right.$$
\end{theorem}
对于$X$和$Y$的期望与方差，我们都可以用一个统一的形式进行表示。

\vspace{2cm}
\begin{remark}
\begin{enumerate}
   \item 当$g(X,Y)=X$时，$X$的数学期望为
    \begin{eqnarray*}
    E(X) &=&\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x p(x ,y) \text{d} y \text{d} x \\
    &=&\int_{-\infty}^{+\infty} x p_{X}(x) \text{d} x
    \end{eqnarray*}
    
    \item 当$g(X,Y)=(X-EX)^{2}$时，$X$的方差为
    \begin{eqnarray*}
\text{Var}(X)&=&E(X-E X)^{2} \\
&=&\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}(x-E(X))^{2} p(x, y)  \text{d} y  \text{d}x \\
&=&\int_{-\infty}^{+\infty}(x-E(X))^{2} p_{X}(x)  \text{d} x
\end{eqnarray*}
\item 当$g(X,Y)=Y$时，$Y$的数学期望为
    \begin{eqnarray*}
    E(Y) &=&\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} y p(x ,y) \text{d} x \text{d} y \\
    &=&\int_{-\infty}^{+\infty} y p_{Y}(y) \text{d} y
    \end{eqnarray*}
    \item 当$g(X,Y)=(Y-EY)^{2}$时，$Y$的方差为
    \begin{eqnarray*}
\text{Var}(Y)&=&E(Y-E Y)^{2} \\
&=&\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}(y-E(Y))^{2} p(x, y)  \text{d} y \text{d} x\\
&=&\int_{-\infty}^{+\infty}(y-E(Y))^{2} p_{Y}(y)  \text{d} y
\end{eqnarray*}
\end{enumerate}
\end{remark}

\begin{example}
在长度为$a$的线段上任取两个点$X$与$Y$，求此两点间的平均长度。
\end{example}
\begin{solution}
因为$X$与$Y$均服从$(0,a)$上的均匀分布且$X$与$Y$相互独立，所以$(X,Y)$的联合密度函数为
$$p(x, y)=\left\{\begin{aligned}
&\frac{1}{a^{2}}&,0<x,y<a\\
&0&,\text{其他}
\end{aligned}\right.$$
两点间的平均长度为
\begin{eqnarray*}
    E(|X-Y|) &=&\int_{0}^{a} \int_{0}^{a}|x-y| \cdot \frac{1}{a^{2}} \text{d} x \text{d} y=\frac{1}{a^{2}}\left(\int_{0}^{a} \int_{0}^{x}(x-y) \text{d} y \text{d} x+\int_{0}^{a} \int_{x}^{a}(y-x) \text{d} y \text{d} x\right) \\
&=&\frac{1}{a^{2}}\left(\int_{0}^{a} \left(x y-\left.\frac{1}{2} y^{2}\right)\right|_{0} ^{x} \text{d} x+\int_{0}^{a} \left(\frac{1}{2} y^{2}-\left.x y\right)\right|_{x} ^{a} \text{d} x\right) \\
&=&\frac{1}{a^{2}} \int_{0}^{a}\left(\frac{1}{2} x^{2}+\frac{1}{2} a^{2}-a x+\frac{1}{2} x^{2}\right) \text{d} x \\
&=&\frac{1}{a^{2}}\left(\frac{1}{2} a^{2} x-\frac{1}{2} a x^{2}+\left.\frac{1}{3} x^{3}\right|_{0} ^{a}\right) = \frac{1}{a^{2}}\left(\frac{1}{2} a^{3}-\frac{1}{2} a^{3}+\frac{1}{3} a^{3}\right)\\
&=&\frac{a}{3}.
\end{eqnarray*}
\end{solution}

以下我们介绍一些期望和方差的性质。
\begin{property}
\begin{enumerate}
    \item 期望与求和可交换：设$(X,Y)$是二维随机变量，则有
    $$E(X+Y) = E(X) + E(Y).$$
    \begin{remark} $n$个随机变量和的期望等于$n$个随机变量期望的和，即
     $$ E\left(\sum_{i=1}^{n} X_i\right) = \sum_{i=1}^{n} E(X_i)
    $$
    \end{remark}
    \item 多个独立随机变量的期望与方差的简便计算公式。
    \begin{enumerate}
        \item 若随机变量$X$和$Y$相互独立，则有
        $$E(XY) = E(X)E(Y).$$
    \begin{proof}
    这里仅证明$(X,Y)$为连续随机变量，离散随机变量的证明过程供学生课后自行完成。其密度函数为$p(x,y)$。因为$X$和$Y$相互独立，所以$p(x,y) = p_X(x)p_Y(y)$。令$g(X,Y) = XY$，则有
     \begin{eqnarray*}
         E(XY) &=& \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} xy p(x,y) \text{d}x \text{d}y\\
         &=& \int_{-\infty}^{\infty}  \int_{-\infty}^{\infty} xy p_X(x) p_Y(y) \text{d}x \text{d}y\\
         &=& \int_{-\infty}^{\infty} x p_X(x)\text{d}x  \cdot\int_{-\infty}^{\infty} y  p_Y(y) \text{d}y\\
         &=& E(X) E(Y).
     \end{eqnarray*}
    \end{proof}
        \begin{remark}
            若$X_1,X_2,\cdots,X_n$相互独立，则有
            $$
            E\left(\prod_{i=1}^n X_i\right) = \prod_{i=1}^n E(X_i).
            $$
        \end{remark}
    \item 若随机变量$X$与$Y$相互独立，则有
    $$
    \text{Var}(X\pm Y) = Var(X) + Var(Y).
    $$
    \begin{proof}
    根据定义， 
        \begin{eqnarray*}
       \text{Var} (X\pm Y) &=& E(X\pm Y - (E(X) \pm E(Y)))^2 = E((X - E(X))\pm (Y-E(Y)))^2\\
        &=& E((X - E(X))^2 + (Y-E(Y))^2 \pm 2(X - E(X))(Y-E(Y)))\\
        &=& E(X - E(X))^2 + E(Y-E(Y))^2 \pm 2E((X - E(X))(Y-E(Y)))\\
        &=& E(X - E(X))^2 + E(Y-E(Y))^2\\
        &=& \text{Var}(X)+\text{Var}(Y),
    \end{eqnarray*}
    最后一个等式成立是因为$E((X - E(X))(Y-E(Y))) = E(XY) - E(X)E(Y) = 0$.
    \end{proof}
    \begin{remark}
    \begin{enumerate}
        \item 若$X_1,X_2,\cdots,X_n$相互独立，则有
        $$
        \text{Var}\left(\sum_{i=1}^n X_i\right) = \sum_{i=1}^n \text{Var}(X_i).
        $$
        \item  若$X_1,X_2,\cdots,X_n$是独立同分布的随机变量，且方差存在，$Var(X_1) = \sigma^2$，则其算术平均数的方差为
        $$
       \text{Var}\left(\frac{1}{n}\sum_{i=1}^n X_i\right) = \frac{1}{n^2} \sum_{i=1}^n \text{Var}(X_i) = \frac{1}{n^2} \sum_{i=1}^n \sigma^2 = \frac{\sigma^2}{n}.
        $$
    \end{enumerate}
    \end{remark}
    \end{enumerate}
\end{enumerate}
\end{property}
\begin{example}
    设一袋中装有$m$个颜色各不相同的球，每次从中任取一个，有放回地摸取$n$次，以$X$表示在$n$次摸球中摸到球的不同颜色的数目，求$E(X)$。
\end{example}
\begin{solution}
令$X_i$表示是否第$i$种颜色的球在$n$次摸球中至少被摸到一次，即
$$
X_i = \left\{
\begin{aligned}
    & 1, & \text{摸到过,}\\
    & 0, & \text{未摸到,}
\end{aligned}\right.i=1,2,\cdots,m.
$$
于是，第$i$种颜色的球在$n$次摸球中未被摸到过的概率为
$$
P(X_i=0) = \left(1-\frac{1}{m} \right)^{n}. 
$$
令$X$为$n$次摸球中不同颜色的数目，则$X = \sum_{i=1}^m X_i$。于是，
\begin{eqnarray*}
    E(X) &=& E\left(\sum_{i=1}^m X_i \right)\\
    &=& \sum_{i=1}^m E(X_i)\\
    &=& \sum_{i=1}^m P(X_i = 1)\\
    &=& \sum_{i=1}^m \left(1-\left(1-\frac{1}{m} \right)^{n}\right)\\
    &=& m \left(1-\left(1-\frac{1}{m}\right)^{n} \right).
\end{eqnarray*}
\end{solution}
\begin{note}
 \vspace{5cm}   
\end{note}

\section{协方差与相关系数}
\subsection{协方差}
在考虑多个随机变量时，每一个随机变量的期望与方差是我们关注的特征数之外，两个随机变量之间的关系也是我们关心的一个特征数。以下我们介绍特征数——协方差。

\begin{definition}{协方差}\label{def:covariance}
设$(X,Y)$是一个二维随机变量，若$$E\left( (X-E(X))(Y-E(Y)) \right) $$存在，则称其为$X$与$Y$的协方差或相关（中心）矩，并记为$\text{Cov}(X,Y)=E\left ( (X-E(X))(Y-E(Y)) \right)$
\end{definition}
\begin{remark}
    \begin{enumerate}
        \item 特别地，$\text{Cov}(X,X)=\text{Var}(X)$；
        \item 通过协方差可以判断两个随机变量之间的关系，即
        \begin{itemize}
    \item $\text{Cov}(X,Y)>0$时，称$X$与$Y$正相关
    \item $\text{Cov}(X,Y)<0$时，称$X$与$Y$负相关
    \item $\text{Cov}(X,Y)=0$时，称$X$与$Y$不相关（毫无关联/非线性关系）
\end{itemize}
    \end{enumerate}
\end{remark}

以下介绍协方差的一些性质。
\begin{property}
\begin{enumerate}
    \item $ \text{Cov}(X,Y)=E(XY)-E(X)E(Y)$；
    
    \item $X$与$Y$独立$\Rightarrow \text{Cov}(X,Y)=0$，反之不然。
    \begin{remark}
        令$X\sim N(0,\sigma^{2}),Y=X^{2}$。我们可以计算
        $$
        \text{Cov}(X,Y) = E(XY) - E(X)E(Y) = E(X^3) = 0.
        $$
    \end{remark}
    
    \item $\text{Var}(X \pm Y)= \text{Var}(X)+\text{Var}(Y) \pm 2\text{Cov}(X, Y)$。
    \begin{remark}
        对任意$n$个随机变量$X_{1},X_{2},\cdots,X_{n}$，有$$\text{Var}\left(\sum_{i=1}^{n} X_{i}\right)=\sum_{i=1}^{n} \text{Var}\left(X_{i}\right)+2 \sum_{i=1}^{n} \sum_{j=1}^{i-1} \text{Cov}\left(X_{i}, X_{j}\right).$$
    \end{remark}
    \item 若$X$与$Y$不相关，则
    $$E(X Y)=E(X)E(Y), \quad \text{且}\quad  \text{Var}(X \pm Y)= \text{Var}(X)+\text{Var}(Y).$$
    \item 协方差的计算与次序无关，即$\text{Cov}(X,Y)=\text{Cov}(Y,X)$。
    
    \item 任意随机变量$X$与常数$a$的协方差为零，即$\text{Cov}(X,a)=0$。
    
    \item 对任意常数$a,b$，有$\text{Cov}(aX,bY)=ab\cdot \text{Cov}(X,Y)$。
    
    \item 对于任意三个随机变量$X,Y,Z$，有$$\text{Cov}(X+Y, Z)=\text{Cov}(X, Z)+\text{Cov}(Y, Z)$$
\end{enumerate}
\end{property}
\subsection{相关系数}

\begin{definition}{相关系数} \label{def:corr}
设$(X,Y)$是一个二维随机变量，且$\text{Var}(X)=\sigma _{X} ^{2} >0, \text{Var}(Y)=\sigma _{Y} ^{2} >0$，则称$$
\text{Corr}(X, Y)=\frac{\text{Cov}(X, Y)}{\sqrt{\text{Var}(X) \cdot \text{Var}(Y)}}=\frac{\text{Cov}(X, Y)}{\sigma_{X} \sigma_{Y}}$$为$X$与$Y$的（线性）相关系数。
\end{definition}
\begin{remark}
    从另一个角度来看相关系数，令$E(X) = \mu_X$，$E(Y) = \mu_Y$。将原始的随机变量进行标准化，即
    $$
    X^{\ast} = \frac{X-\mu_{X}}{\sigma_{X}} , \quad Y^{\ast} = \frac{Y-\mu_{Y}}{\sigma_{Y}}. 
    $$
    经过标准化后的两个随机变量的协方差为
    \begin{eqnarray*}
        \text{Cov}(X^{\ast},Y^{\ast}) &=& \text{Cov}\left(\frac{X-\mu_{X}}{\sigma_{X}}, \frac{Y-\mu_{Y}}{\sigma_{Y}}\right)\\
        &=& \frac{1}{\sigma_X\sigma_Y} \text{Cov}(X,Y)\\
        &=& \text{Corr}(X,Y).
    \end{eqnarray*}
\end{remark}
\begin{example}
    证明二维正态分布$\left(\mu_{X}, \mu_{Y}, \sigma_{X}^{2}, \sigma_{Y}^{2}, \rho\right)$的相关系数为$\rho$。
\end{example}
\begin{solution}
    首先，计算协方差
\begin{eqnarray*}
\text{Cov}(X, Y) &=&E((X-E(X))(Y-E(Y)))\\
&=& \frac{1}{2 \pi \sqrt{\sigma_{X}^{2} \sigma_{Y}^{2}(1-\rho ^{2})}} \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}\left(x-\mu_{X}\right)\left(y-\mu_{Y}\right) \\
&& \cdot \exp \left\{-\frac{1}{2\left(1-\rho^{2}\right)}\left[\frac{\left(x-\mu_{X}\right)^{2}}{\sigma_{1}^{2}}-2 \rho \frac{\left(x-\mu_{X}\right)\left(y-\mu_{Y}\right)}{\sigma_{1} \sigma_{2}}+\frac{\left(y-\mu_{Y}\right)^{2}}{\sigma_{2}^{2}}\right]\right\} \text{d} x \text{d} y \\
&=& \frac{1}{2 \pi \sqrt{\sigma_{X}^{2} \sigma_{Y}^{2}\left(1-\rho^{2}\right)}} \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}\left(x-\mu_{X}\right)\left(y-\mu_{Y}\right)\cdot \\
&& \cdot  \exp \left\{-\frac{1}{2\left(1-\rho^{2}\right)}\left[\left(\frac{x-\mu_{X}}{\sigma_{X}}-\rho \frac{y-\mu_{Y}}{\sigma_{Y}}\right)^{2}+\left(\sqrt{1-\rho^{2}} \frac{y-\mu_{Y}}{\sigma_{Y}}\right)^{2}\right]\right\} \text{d} x \text{d} y
\end{eqnarray*}
令$$u=\frac{1}{\sqrt{1-\rho^{2}}}\left(\frac{x-\mu_{X}}{\sigma_{X}}-\rho  \frac{\left(y-\mu_{Y}\right)}{\sigma_{Y}}\right), \quad \text{且}\quad v=\frac{y-\mu_{Y}}{\sigma_{Y}}$$
则
\begin{eqnarray*}
\left\{\begin{aligned}
    &x-\mu_{X}=\sigma_{X}\left(u \sqrt{1-\rho^{2}}+\rho v\right),\\
    & y-\mu_{Y}=\sigma_{Y} v,
\end{aligned}\right.
 \quad \text{且}\quad
|J|=\left|\begin{matrix}
\sqrt{1-\rho^{2}} \sigma_{X} & \rho \sigma_{X} \\
0 & \sigma_{Y}
\end{matrix}\right|=\sqrt{1-\rho^{2}} \sigma_{X} \sigma_{Y} 
\end{eqnarray*}
\begin{eqnarray*}
\text{Cov}\left(X, Y\right)&=& \frac{1}{2 \pi \sqrt{\sigma_{X}^{2} \sigma_{Y}^{2}\left(1-\rho^{2}\right)}} \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}\left(\sigma_{X}\left(u \sqrt{1-\rho^{2}}+\rho v\right)\right)\left(\sigma_{Y} v\right) \\
&& \cdot \exp \left\{-\frac{1}{2}\left[u^{2}+v^{2}\right]\right\} \cdot \sqrt{1-\rho^{2}} \cdot \sigma_{X} \sigma_{Y} \text{d} u \text{d} v \\
&=& \frac{\sigma_{X} \sigma_{Y}}{2 \pi} \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}\left(u v \sqrt{1-\rho^{2}}+\rho v^{2}\right) \exp \left\{-\frac{1}{2}\left(u^{2}+v^{2}\right)\right\} \text{d} u \text{d} v
\end{eqnarray*}
注意到\begin{eqnarray*}
&&\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} u v \exp \left\{-\frac{1}{2}\left(u^{2}+v^{2}\right)\right\} \text{d} u \text{d} v=\int_{-\infty}^{+\infty} u \exp \left\{-\frac{1}{2} u^{2}\right\} \text{d} u \cdot \int_{-\infty}^{+\infty} v \exp \left\{-\frac{1}{2} v^{2}\right\} \text{d} v=0 \\
&&\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} v^{2} \exp \left\{-\frac{1}{2}\left(u^{2}+v^{2}\right)\right\} \text{d} u \text{d} v=\int_{-\infty}^{+\infty} \exp \left\{-\frac{1}{2}\left(u^{2}\right)\right\} \text{d} u \cdot \int_{-\infty}^{+\infty} v^{2} \exp \left\{-\frac{1}{2} v^{2}\right\} \text{d} v \\
&=&2 \pi \int_{-\infty}^{+\infty} \frac{1}{\sqrt{2 \pi}} \exp \left\{-\frac{1}{2} u^{2}\right\} \text{d} u \int_{-\infty}^{+\infty} v^{2} \cdot \frac{1}{\sqrt{2 \pi}} \exp \left\{-\frac{1}{2} v^{2}\right\} \text{d} v=1 \cdot E\left(v^{2}\right) \cdot 2 \pi=2 \pi .
\end{eqnarray*}
则\begin{eqnarray*}
\text{Cov}(X, Y)=\frac{\sigma_{X} \sigma_{Y}}{2 \pi} \cdot \rho \cdot 2 \pi=\rho \sigma_{X} \sigma_{Y} \\
\text{Corr}(X, Y)=\frac{\text{Cov}(X ,Y)}{\sqrt{\text{Var}(X) \text{Var}(Y)}}=\frac{\rho \sigma_{X} \sigma_{Y}}{\sigma_{X} \sigma_{Y}}=\rho.
\end{eqnarray*}
\end{solution}


\begin{theorem}[Schwarz不等式]
对任意二维随机变量$(X,Y)$，若$X$与$Y$的方差都存在，且记$\sigma_{X}^{2}=\text{Var}(X),\sigma_{Y}^{2}=\text{Var}(Y)$，则有$$(\text{Cov}(X, Y))^{2} \leq \sigma_{X}^{2} \sigma_{Y}^{2}.$$
\end{theorem}
\begin{proof}
    不妨设$\sigma_{X}^{2}>0$，设函数\begin{eqnarray*}
       g(t) &=&E(t(X-E(X))+(Y-E(Y)))^{2}  \\
&=&t^{2} \sigma_{X}^{2}+2t\text{Cov}\left(X, Y\right)+\sigma_{Y}^{2}.
    \end{eqnarray*}
因为$g(t)$是一个非负随机变量的期望，所以，$g(t)$恒非负。而且，这个二次函数的开口向上，其只有一个或零个零根。所以，其判别式小于或等于零，即$$ {(2 \text{Cov}(X, Y))^{2}-4 \sigma_{X}^{2} \sigma_{Y}^{2} \leqslant 0}. $$
也就是说，
$$(\text{Cov}(X, Y))^{2} \leqslant \text{Var}(X) \text{Var}(Y).$$
\end{proof}


\begin{property}
\begin{enumerate}
   \item $\left | \text{Corr}(X,Y) \right | \le1$；
    
    \item $\text{Corr}(X,Y)=\pm1\Leftrightarrow X$与$Y$之间几乎处处有线性关系，即存在$a \neq0$与$b$，使得$$P(Y=aX+b)=1$$其中，当$\text{Corr}(X,Y)=1$时，有$a>0$；当$\text{Corr}(X,Y)=-1$时，有$a<0$。
    
    \begin{remark}
    \begin{itemize}
        \item $\text{Corr}(X,Y)=0$，则称$X$与$Y$不相关；
        \item $\text{Corr}(X,Y)=+1$，则称$X$与$Y$完全正相关；
        \item $\text{Corr}(X,Y)=-1$，则称$X$与$Y$完全负相关；
        \item $0<\left | \text{Corr}(X,Y) \right | <1$，则称$X$与$Y$有“一定程度”的线性关系。
\end{itemize}
    \end{remark}
    \item 在二维正态分布$N\left(\mu_{X}, \mu_{Y}, \sigma_{X}^{2}, \sigma_{Y}^{2}, \rho\right)$场合，不相关与独立是等价的。
\end{enumerate}
\end{property}
\section{期望向量与协方差矩阵}
\begin{definition}
记$n$维随机向量$\bm{X}=\left(X_{1}, X_{2}, \cdots, X_{n}\right)'$，若其每个分量的数学期望都存在，则称$$E(\bm{X})=\left(E\left(X_{1}\right), E\left(X_{2}\right), \cdots, E\left(X_{n}\right)\right)'$$为$n$维随机向量的数学期望向量，而称$$
E(\bm{X}-E(\bm{X}))(\bm{X}-E(\bm{X}))'\\
=\left(\begin{matrix}
\text{Var}\left(X_{1}\right) & \text{Cov}\left(X_{1}, X_{2}\right) & \cdots & \text{Cov}\left(X_{1}, X_{n}\right) \\
\text{Cov}\left(X_{2}, X_{1}\right) & \text{Var}\left(X_{2}\right) & \cdots & \text{Cov}\left(X_{2}, X_{n}\right) \\
\vdots & \vdots & & \vdots \\
\text{Cov}\left(X_{n}, X_{1}\right) & \text{Cov}\left(X_{n}, X_{2}\right) & \cdots & \text{Var}\left(X_{n}\right)
\end{matrix}\right)
$$为该随机向量的方差—协方差矩阵，记为$\text{Cov}(\bm{X})$
\end{definition}
\begin{theorem}
$n$维随机向量的协方差矩阵$\text{Cov}(\bm{X})=\left\{\text{Cov}\left(X_{i}, X_{j}\right)\right\}_{n\times n}$是一个对称非负定矩阵。
\end{theorem}
\section{习题}
\begin{enumerate}
    \item 股票市场交易者购入100股A股票和200股B股票。设X和Y分别表示在一段时间内A股票和B股票的价格波动。并假设X和Y的联合分布列是定义在一个特定的整数集上的离散均匀分布，且这个整数集满足
$$-2\leq x\leq 4,\quad -1\leq y-x\leq 1.$$
\begin{enumerate}
    \item 求$X$和$Y$的边际分布列及均值；
\item 求该交易者获取利润的均值。
\end{enumerate}
\item 求掷$n$颗骰子出现点数之和的数学期望与方差。
\item 设二维随机变量$(X,Y)$的联合密度函数为
$$
p(x,y) = \begin{aligned}
    & 1, &  |y| < x,0 < x < 1,\\
    & 0, & \text{其他}.
\end{aligned}
$$
求$E(X),E(Y),\text{Cov}(X,Y)$。

\item  设随机变量X有密度函数$p(x)$，且密度函数$p(x)$是偶函数，假定$E|X|^3 < +\infty$。证明：$X$与$Y = X^2$不相关、但不独立。

\item 如今有四个随机变量：$W, X, Y, Z.$ 且满足
$$
E(W) = E(X) = E(Y) = E(Z) = 0$$
$$
\text{Var}(W) = \text{Var}(X) = \text{Var}(Y) = \text{Var}(Z) = 1
$$
假设$W, X, Y, Z$ 是两两不相关的。求$R,S$的相关系数$\text{Corr}(R,S)$以及$R,T$的相关系数$\text{Corr}(R,T)$. 其中$R = W + X, S = X + Y,T = Y + Z$。
\end{enumerate}